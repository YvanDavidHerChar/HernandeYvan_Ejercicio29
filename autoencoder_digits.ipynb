{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.preprocessing\n",
    "import torchvision.models\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8) (1797,)\n"
     ]
    }
   ],
   "source": [
    "numeros = sklearn.datasets.load_digits()\n",
    "imagenes = numeros['images']  # Hay 1797 digitos representados en imagenes 8x8\n",
    "n_imagenes = len(imagenes)\n",
    "Y = numeros['target']\n",
    "print(np.shape(imagenes), np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 1, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = imagenes[:600]\n",
    "Y_train = Y[:600]\n",
    "train = torch.autograd.Variable(torch.Tensor(X_train).float())\n",
    "targets = torch.autograd.Variable(torch.Tensor(Y_train).long())\n",
    "mean = train.mean(dim=0)\n",
    "std = train.std(dim=0)\n",
    "std[std==0]=1.0\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train[i] = (train[i]-mean)/std\n",
    "np.shape(train)\n",
    "x_train = train.unsqueeze(1)\n",
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 18, 5, 5])\n",
      "torch.Size([600, 5, 3, 3])\n",
      "torch.Size([600, 18, 4, 4])\n",
      "torch.Size([600, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "n = torch.nn.Conv2d(1, 16, kernel_size=4, stride=1) # in-channels = 1, out-channels = 10, kernel=4\n",
    "new_tensor = n(x_train)\n",
    "print(new_tensor.size())\n",
    "\n",
    "n = torch.nn.Conv2d(16,6,kernel_size=3)\n",
    "feature_maps = n(new_tensor)\n",
    "print(feature_maps.size())\n",
    "\n",
    "n = torch.nn.ConvTranspose2d(6,16,kernel_size=2)\n",
    "feature_maps = n(feature_maps)\n",
    "print(feature_maps.size())\n",
    "\n",
    "n = torch.nn.ConvTranspose2d(16,1,kernel_size=2, stride=2)\n",
    "feature_maps = n(feature_maps)\n",
    "print(feature_maps.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=4, stride=1),\n",
    "            \n",
    "            torch.nn.Conv2d(16,6,kernel_size=3))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(             \n",
    "            torch.nn.ConvTranspose2d(6,16,kernel_size=3),\n",
    "            \n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=4, stride=1))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 300\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1E-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/300], loss:0.9367\n",
      "epoch [2/300], loss:0.7831\n",
      "epoch [3/300], loss:0.6829\n",
      "epoch [4/300], loss:0.6621\n",
      "epoch [5/300], loss:0.6010\n",
      "epoch [6/300], loss:0.5758\n",
      "epoch [7/300], loss:0.5541\n",
      "epoch [8/300], loss:0.5261\n",
      "epoch [9/300], loss:0.5032\n",
      "epoch [10/300], loss:0.4888\n",
      "epoch [11/300], loss:0.4654\n",
      "epoch [12/300], loss:0.4382\n",
      "epoch [13/300], loss:0.4224\n",
      "epoch [14/300], loss:0.4133\n",
      "epoch [15/300], loss:0.4018\n",
      "epoch [16/300], loss:0.3873\n",
      "epoch [17/300], loss:0.3741\n",
      "epoch [18/300], loss:0.3653\n",
      "epoch [19/300], loss:0.3578\n",
      "epoch [20/300], loss:0.3484\n",
      "epoch [21/300], loss:0.3389\n",
      "epoch [22/300], loss:0.3310\n",
      "epoch [23/300], loss:0.3237\n",
      "epoch [24/300], loss:0.3154\n",
      "epoch [25/300], loss:0.3069\n",
      "epoch [26/300], loss:0.2995\n",
      "epoch [27/300], loss:0.2932\n",
      "epoch [28/300], loss:0.2872\n",
      "epoch [29/300], loss:0.2813\n",
      "epoch [30/300], loss:0.2755\n",
      "epoch [31/300], loss:0.2703\n",
      "epoch [32/300], loss:0.2657\n",
      "epoch [33/300], loss:0.2610\n",
      "epoch [34/300], loss:0.2564\n",
      "epoch [35/300], loss:0.2524\n",
      "epoch [36/300], loss:0.2489\n",
      "epoch [37/300], loss:0.2453\n",
      "epoch [38/300], loss:0.2417\n",
      "epoch [39/300], loss:0.2380\n",
      "epoch [40/300], loss:0.2346\n",
      "epoch [41/300], loss:0.2313\n",
      "epoch [42/300], loss:0.2283\n",
      "epoch [43/300], loss:0.2257\n",
      "epoch [44/300], loss:0.2231\n",
      "epoch [45/300], loss:0.2205\n",
      "epoch [46/300], loss:0.2180\n",
      "epoch [47/300], loss:0.2157\n",
      "epoch [48/300], loss:0.2136\n",
      "epoch [49/300], loss:0.2114\n",
      "epoch [50/300], loss:0.2092\n",
      "epoch [51/300], loss:0.2071\n",
      "epoch [52/300], loss:0.2051\n",
      "epoch [53/300], loss:0.2031\n",
      "epoch [54/300], loss:0.2013\n",
      "epoch [55/300], loss:0.1995\n",
      "epoch [56/300], loss:0.1976\n",
      "epoch [57/300], loss:0.1957\n",
      "epoch [58/300], loss:0.1939\n",
      "epoch [59/300], loss:0.1921\n",
      "epoch [60/300], loss:0.1902\n",
      "epoch [61/300], loss:0.1883\n",
      "epoch [62/300], loss:0.1865\n",
      "epoch [63/300], loss:0.1847\n",
      "epoch [64/300], loss:0.1829\n",
      "epoch [65/300], loss:0.1811\n",
      "epoch [66/300], loss:0.1794\n",
      "epoch [67/300], loss:0.1778\n",
      "epoch [68/300], loss:0.1762\n",
      "epoch [69/300], loss:0.1747\n",
      "epoch [70/300], loss:0.1733\n",
      "epoch [71/300], loss:0.1718\n",
      "epoch [72/300], loss:0.1705\n",
      "epoch [73/300], loss:0.1693\n",
      "epoch [74/300], loss:0.1681\n",
      "epoch [75/300], loss:0.1669\n",
      "epoch [76/300], loss:0.1658\n",
      "epoch [77/300], loss:0.1647\n",
      "epoch [78/300], loss:0.1637\n",
      "epoch [79/300], loss:0.1627\n",
      "epoch [80/300], loss:0.1617\n",
      "epoch [81/300], loss:0.1608\n",
      "epoch [82/300], loss:0.1599\n",
      "epoch [83/300], loss:0.1590\n",
      "epoch [84/300], loss:0.1581\n",
      "epoch [85/300], loss:0.1572\n",
      "epoch [86/300], loss:0.1564\n",
      "epoch [87/300], loss:0.1555\n",
      "epoch [88/300], loss:0.1547\n",
      "epoch [89/300], loss:0.1539\n",
      "epoch [90/300], loss:0.1531\n",
      "epoch [91/300], loss:0.1523\n",
      "epoch [92/300], loss:0.1515\n",
      "epoch [93/300], loss:0.1507\n",
      "epoch [94/300], loss:0.1500\n",
      "epoch [95/300], loss:0.1493\n",
      "epoch [96/300], loss:0.1486\n",
      "epoch [97/300], loss:0.1479\n",
      "epoch [98/300], loss:0.1473\n",
      "epoch [99/300], loss:0.1466\n",
      "epoch [100/300], loss:0.1460\n",
      "epoch [101/300], loss:0.1455\n",
      "epoch [102/300], loss:0.1449\n",
      "epoch [103/300], loss:0.1444\n",
      "epoch [104/300], loss:0.1438\n",
      "epoch [105/300], loss:0.1434\n",
      "epoch [106/300], loss:0.1429\n",
      "epoch [107/300], loss:0.1424\n",
      "epoch [108/300], loss:0.1420\n",
      "epoch [109/300], loss:0.1416\n",
      "epoch [110/300], loss:0.1412\n",
      "epoch [111/300], loss:0.1408\n",
      "epoch [112/300], loss:0.1404\n",
      "epoch [113/300], loss:0.1400\n",
      "epoch [114/300], loss:0.1397\n",
      "epoch [115/300], loss:0.1394\n",
      "epoch [116/300], loss:0.1391\n",
      "epoch [117/300], loss:0.1388\n",
      "epoch [118/300], loss:0.1385\n",
      "epoch [119/300], loss:0.1382\n",
      "epoch [120/300], loss:0.1380\n",
      "epoch [121/300], loss:0.1377\n",
      "epoch [122/300], loss:0.1375\n",
      "epoch [123/300], loss:0.1373\n",
      "epoch [124/300], loss:0.1370\n",
      "epoch [125/300], loss:0.1368\n",
      "epoch [126/300], loss:0.1366\n",
      "epoch [127/300], loss:0.1364\n",
      "epoch [128/300], loss:0.1362\n",
      "epoch [129/300], loss:0.1360\n",
      "epoch [130/300], loss:0.1358\n",
      "epoch [131/300], loss:0.1356\n",
      "epoch [132/300], loss:0.1354\n",
      "epoch [133/300], loss:0.1352\n",
      "epoch [134/300], loss:0.1350\n",
      "epoch [135/300], loss:0.1348\n",
      "epoch [136/300], loss:0.1346\n",
      "epoch [137/300], loss:0.1344\n",
      "epoch [138/300], loss:0.1342\n",
      "epoch [139/300], loss:0.1340\n",
      "epoch [140/300], loss:0.1338\n",
      "epoch [141/300], loss:0.1336\n",
      "epoch [142/300], loss:0.1334\n",
      "epoch [143/300], loss:0.1333\n",
      "epoch [144/300], loss:0.1331\n",
      "epoch [145/300], loss:0.1329\n",
      "epoch [146/300], loss:0.1327\n",
      "epoch [147/300], loss:0.1326\n",
      "epoch [148/300], loss:0.1324\n",
      "epoch [149/300], loss:0.1322\n",
      "epoch [150/300], loss:0.1321\n",
      "epoch [151/300], loss:0.1319\n",
      "epoch [152/300], loss:0.1318\n",
      "epoch [153/300], loss:0.1316\n",
      "epoch [154/300], loss:0.1314\n",
      "epoch [155/300], loss:0.1313\n",
      "epoch [156/300], loss:0.1312\n",
      "epoch [157/300], loss:0.1310\n",
      "epoch [158/300], loss:0.1309\n",
      "epoch [159/300], loss:0.1308\n",
      "epoch [160/300], loss:0.1306\n",
      "epoch [161/300], loss:0.1305\n",
      "epoch [162/300], loss:0.1304\n",
      "epoch [163/300], loss:0.1303\n",
      "epoch [164/300], loss:0.1302\n",
      "epoch [165/300], loss:0.1301\n",
      "epoch [166/300], loss:0.1299\n",
      "epoch [167/300], loss:0.1299\n",
      "epoch [168/300], loss:0.1298\n",
      "epoch [169/300], loss:0.1297\n",
      "epoch [170/300], loss:0.1296\n",
      "epoch [171/300], loss:0.1295\n",
      "epoch [172/300], loss:0.1294\n",
      "epoch [173/300], loss:0.1293\n",
      "epoch [174/300], loss:0.1293\n",
      "epoch [175/300], loss:0.1292\n",
      "epoch [176/300], loss:0.1292\n",
      "epoch [177/300], loss:0.1291\n",
      "epoch [178/300], loss:0.1290\n",
      "epoch [179/300], loss:0.1290\n",
      "epoch [180/300], loss:0.1289\n",
      "epoch [181/300], loss:0.1289\n",
      "epoch [182/300], loss:0.1288\n",
      "epoch [183/300], loss:0.1288\n",
      "epoch [184/300], loss:0.1288\n",
      "epoch [185/300], loss:0.1287\n",
      "epoch [186/300], loss:0.1287\n",
      "epoch [187/300], loss:0.1287\n",
      "epoch [188/300], loss:0.1286\n",
      "epoch [189/300], loss:0.1286\n",
      "epoch [190/300], loss:0.1286\n",
      "epoch [191/300], loss:0.1285\n",
      "epoch [192/300], loss:0.1285\n",
      "epoch [193/300], loss:0.1285\n",
      "epoch [194/300], loss:0.1285\n",
      "epoch [195/300], loss:0.1284\n",
      "epoch [196/300], loss:0.1284\n",
      "epoch [197/300], loss:0.1284\n",
      "epoch [198/300], loss:0.1283\n",
      "epoch [199/300], loss:0.1283\n",
      "epoch [200/300], loss:0.1283\n",
      "epoch [201/300], loss:0.1283\n",
      "epoch [202/300], loss:0.1282\n",
      "epoch [203/300], loss:0.1282\n",
      "epoch [204/300], loss:0.1282\n",
      "epoch [205/300], loss:0.1282\n",
      "epoch [206/300], loss:0.1281\n",
      "epoch [207/300], loss:0.1281\n",
      "epoch [208/300], loss:0.1281\n",
      "epoch [209/300], loss:0.1281\n",
      "epoch [210/300], loss:0.1280\n",
      "epoch [211/300], loss:0.1280\n",
      "epoch [212/300], loss:0.1280\n",
      "epoch [213/300], loss:0.1279\n",
      "epoch [214/300], loss:0.1279\n",
      "epoch [215/300], loss:0.1279\n",
      "epoch [216/300], loss:0.1278\n",
      "epoch [217/300], loss:0.1278\n",
      "epoch [218/300], loss:0.1278\n",
      "epoch [219/300], loss:0.1277\n",
      "epoch [220/300], loss:0.1277\n",
      "epoch [221/300], loss:0.1277\n",
      "epoch [222/300], loss:0.1276\n",
      "epoch [223/300], loss:0.1276\n",
      "epoch [224/300], loss:0.1276\n",
      "epoch [225/300], loss:0.1275\n",
      "epoch [226/300], loss:0.1275\n",
      "epoch [227/300], loss:0.1275\n",
      "epoch [228/300], loss:0.1274\n",
      "epoch [229/300], loss:0.1274\n",
      "epoch [230/300], loss:0.1274\n",
      "epoch [231/300], loss:0.1273\n",
      "epoch [232/300], loss:0.1273\n",
      "epoch [233/300], loss:0.1273\n",
      "epoch [234/300], loss:0.1272\n",
      "epoch [235/300], loss:0.1272\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_ar = np.zeros(num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    output = model(x_train)\n",
    "    loss = distance(output, x_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_ar[epoch] = loss.item()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(num_epochs), loss_ar)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform = model(x_train)\n",
    "latent_space = model.encoder(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra los resultados de las cuatro capas de convolucion\n",
    "plt.figure(figsize=(14,14))\n",
    "offset = 16\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+1) #imagenes originales\n",
    "    plt.imshow(x_train[i+offset][0].detach().numpy())\n",
    "    #lt.title(train_loader.dataset.classes[train_loader.dataset.targets[i+offset]] )\n",
    "    \n",
    "    j=0 # las imagenes reconstruidas por el autoencoder\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(x_transform[i+offset][0].detach().numpy())\n",
    "    \n",
    "    j=1 # una de las capas de la representacion latente\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(latent_space[i+offset][2].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
